# Gemini API Rate Limit & Quota Management

## ğŸš¨ Problem: Rate Limit Exceeded (429 Error)

You're experiencing `429 RESOURCE_EXHAUSTED` errors because you're hitting Gemini API quotas.

## ğŸ“Š Gemini API Free Tier Limits

### Embedding API (gemini-embedding-001)
- **Requests per minute (RPM)**: 1,500
- **Requests per day (RPD)**: 1,500
- **Tokens per minute (TPM)**: 1,000,000

### Text Generation API (gemini-2.5-flash)
- **Requests per minute (RPM)**: 15
- **Requests per day (RPD)**: 1,500
- **Tokens per minute (TPM)**: 1,000,000

### âš ï¸ gemini-2.5-pro (NOT AVAILABLE on Free Tier)
- **Free Tier Quota**: **ZERO** (0 RPM, 0 RPD)
- **Error**: "Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0"
- **Solution**: Use `gemini-2.5-flash` instead

## âœ… Fixes Implemented

### 1. **Reduced Batch Sizes**
- `generateEmbeddings`: 5 â†’ **2 items per batch**
- `batchEmbedChunks`: 10 parallel â†’ **1 sequential (with delays)**

### 2. **Increased Delays**
- Between batches: 1s â†’ **3s**
- Between chunks: none â†’ **2s** (5s after errors)

### 3. **Smart Quota Exhaustion Handling**
```typescript
// Detects 429 errors and gracefully degrades
// Fills remaining chunks with zero embeddings instead of failing
```

### 4. **Reduced Retries**
- Retry attempts: 3 â†’ **2** (less quota waste)
- Fast-fail on quota exhaustion (no retries)

### 5. **Sequential Processing**
- Changed from parallel to **sequential** for large batch operations
- Prevents quota burst exhaustion

## ğŸ”§ How to Use

### Option 1: Wait for Quota Reset
Free tier quotas reset:
- **Per minute**: Resets every 60 seconds
- **Per day**: Resets at midnight UTC

Check your usage: https://ai.dev/usage?tab=rate-limit

### Option 2: Upgrade to Paid Plan

**Pay-as-you-go** pricing:
- Embeddings: **$0.00025 per 1K characters** (very cheap!)
- Text Generation: **$0.075 per 1M input tokens**

Benefits:
- **Higher quotas**: 10,000+ RPM
- **No daily limits**
- **Faster processing**

Sign up: https://makersuite.google.com/app/billing

### Option 3: Process Smaller Batches

Instead of uploading large documents all at once:

1. **Split uploads** into smaller chunks
2. **Process documents one at a time**
3. **Limit chunk count** when testing

## ğŸ¯ Best Practices

### For Development
```typescript
// Limit chunks during testing
const MAX_CHUNKS_FOR_TESTING = 20;
const chunks = allChunks.slice(0, MAX_CHUNKS_FOR_TESTING);
```

### For Production
1. **Monitor usage** regularly at https://ai.dev/usage
2. **Set up billing alerts** before hitting limits
3. **Implement queue system** for large uploads
4. **Cache embeddings** to avoid re-processing

## ğŸ“ˆ Rate Limit Calculations

### Example: 70-chunk document
```
Old approach:
- Batch size: 10 parallel
- Delay: 1s between batches
- Total time: ~8 seconds
- Result: ğŸ”¥ QUOTA EXHAUSTED

New approach:
- Sequential processing
- Delay: 2s per chunk
- Total time: ~140 seconds (2.3 minutes)
- Result: âœ… SUCCESS
```

### Sustainable Processing Rate
With free tier:
- **Embeddings**: ~1 request per 2.4 seconds (2,500 requests/hour max)
- **Safe rate**: 1 request per 3-5 seconds to be conservative

## ğŸ” Monitoring Your Usage

Check real-time usage:
```bash
# Visit this URL
https://ai.dev/usage?tab=rate-limit

# Monitor:
- Current quota usage
- Remaining requests
- Reset time
```

## ğŸ’¡ Alternative Solutions

### 1. Use Batch API (Coming Soon)
Gemini Batch API offers:
- **50% lower cost**
- Higher throughput
- Better for bulk operations

### 2. Switch to Different Embedding Provider
Consider alternatives for high-volume use:
- **OpenAI embeddings**: Higher limits, paid only
- **Cohere embeddings**: Good free tier
- **Local embeddings**: sentence-transformers (free, no limits)

### 3. Implement Caching
```typescript
// Cache embeddings in database
// Check if embedding exists before generating new one
const cachedEmbedding = await checkEmbeddingCache(text);
if (cachedEmbedding) return cachedEmbedding;
```

## ğŸš€ Quick Fix Commands

### If you're stuck with 429 errors:

1. **Stop the server**:
   ```bash
   # Press Ctrl+C in terminal
   ```

2. **Wait 1-2 minutes** for quota to reset

3. **Restart with smaller batch**:
   ```bash
   npm run dev
   ```

4. **Upload smaller documents** first

## ğŸ“ Need Higher Limits?

Contact Google AI for:
- Enterprise quotas
- Custom pricing
- Volume discounts
- Priority support

---

## âœ… Recent Fixes

### December 16, 2025
1. **Fixed syllabus extraction quota error**
   - Changed: `gemini-2.5-pro` â†’ `gemini-2.5-flash`
   - Reason: `gemini-2.5-pro` has ZERO free tier quota
   - File: `src/lib/syllabus-extraction.ts`

2. **Implemented aggressive rate limiting**
   - Reduced batch sizes (5 â†’ 2, 10 â†’ 1)
   - Increased delays (1s â†’ 3s, added 2s per chunk)
   - Sequential processing for large batches

---

**Current Configuration:**
- âœ… Aggressive rate limiting enabled
- âœ… Sequential processing for large batches
- âœ… Quota exhaustion detection
- âœ… Graceful degradation (zero embeddings on failure)
- âœ… Smart retry logic (fast-fail on 429)
- âœ… Using `gemini-2.5-flash` (free tier available)
- âŒ NOT using `gemini-2.5-pro` (no free tier)

**These changes significantly reduce quota usage but increase processing time. This is the trade-off for staying within free tier limits.**
